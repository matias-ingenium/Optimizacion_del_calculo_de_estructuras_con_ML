{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjZ7IeSaGhKS"
   },
   "source": [
    "# Contexto teórico para la pasantía\n",
    "\n",
    "## Introducción al problema físico\n",
    "\n",
    "Queremos estudiar el comportamiento de la elasticidad de distintos objetos como barras y losas en un espacio $\\Omega$. Para esto tenemos que ver las ecuaciones diferenciales que los gobiernan. Las ecuaciones de elasticidad estan definidas por otras 4 ecuaciones:\n",
    "\n",
    "1. **Ecuación de equilibrio:** relaciones entre tensiones de elementos estructurales y fuerzas externas.  \n",
    "   $\\forall x \\in \\Omega$  \n",
    "   \n",
    "   $$\n",
    "   \\left\\{\n",
    "   \\begin{aligned}\n",
    "   \\nabla \\cdot  \\sigma(x) + b &= 0 \\\\\n",
    "   \\sigma(x) &= \\sigma(x)^T\n",
    "   \\end{aligned}\n",
    "   \\right.\n",
    "   $$\n",
    "\n",
    "   Donde $\\sigma$ es el tensor de tensiones y $b$ es una fuerza.\n",
    "\n",
    "\n",
    "\n",
    "2. **Ecuación constitutiva:** relación entre tensiones y deformaciones de elementos.  \n",
    "\n",
    "   $$\n",
    "   \\sigma = C[\\epsilon]\n",
    "   $$\n",
    "\n",
    "   que es equivalente a:  \n",
    "\n",
    "   $$\n",
    "   \\sigma(\\epsilon) = \\lambda \\, \\text{Tr}(\\epsilon) I + 2\\mu\\epsilon\n",
    "   $$\n",
    "\n",
    "   Donde $\\text{Tr}$ es la traza, $\\epsilon$ es el tensor de deformaciones y $\\lambda, \\mu$ son los parámetros de Lamé (relacionados con el módulo de Young y el coeficiente de Poisson).\n",
    "\n",
    "\n",
    "\n",
    "3. **Relaciones cinemáticas:** relación entre deformaciones y desplazamientos.  \n",
    "\n",
    "   $$\n",
    "   \\epsilon = \\frac{1}{2} (\\nabla u + \\nabla u^T)\n",
    "   $$\n",
    "\n",
    "   Donde $u$ es el campo de desplazamientos.\n",
    "\n",
    "\n",
    "\n",
    "4. **Condiciones de contorno:** valores conocidos de desplazamientos y fuerzas externas.  \n",
    "\n",
    "   $$\n",
    "   \\left\\{\n",
    "   \\begin{aligned}\n",
    "   u &= \\hat{u} \\\\\n",
    "   \\sigma[n] &= \\hat{t}\n",
    "   \\end{aligned}\n",
    "   \\right.\n",
    "   $$\n",
    "\n",
    "   La primera ecuación se da en $\\Gamma_u$ (contorno de desplazamientos) y la segunda en $\\Gamma_t$ (contorno de tensiones).  \n",
    "   $\\hat{u}$ es el campo vectorial de desplazamientos impuestos o conocidos, y $\\hat{t}$ es el campo vectorial de tensiones aplicadas.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Problema de Elasticidad Lineal**\n",
    "\n",
    "El PEL consiste en encontrar las magnitudes: σ, ε y u que verifican simultáneamente las condiciones establecidas por las ecuaciones anteriores. Esta es usualmente llamada la formuación fuerte del\n",
    "problema de Elasticidad Lineal.\n",
    "A partir de las ecuaciones de la formulación fuerte del PEL es posible obtener formulaciones débiles o\n",
    "integrales, las cuales facilitan la posterior presentación de métodos numéricos de resolución.\n",
    "\n",
    "**Teorema de trabajo virtual**\n",
    "\n",
    "Si se considera un campo tensorial $\\sigma$ en equilibrio con las fuerzas externas y un campo de desplazamientos virtuales $w$ compatible con las condiciones cinemáticas de contorno, entonces se cumple que:\n",
    "\n",
    "$\\int_\\Omega \\sigma : \\epsilon(w) dV = \\int_{\\Gamma_t} \\hat{t} \\cdot w dS + \\int_\\Omega b \\cdot w dV$  $\\forall w \\in V_u $\n",
    "donde $V_u$ es el conjunto de desplazamientos virtuales compatibles con los vínculos de apoyo.\n",
    "\n",
    "\n",
    "**Formulación débil**\n",
    "\n",
    "Considerando la ecuación constitutiva del material elástico lineal se puede reescribir la ecuación anterior\n",
    "obteniendo una nueva formulación del PEL. Esta formulación consiste en hallar el campo de desplazamientos\n",
    "u tal que se cumple:\n",
    "\n",
    "$\\int_\\Omega C[\\epsilon(u)] : \\epsilon(w) dV = \\int_{\\Gamma_t} \\hat{t} \\cdot w dS + \\int_\\Omega b \\cdot w dV$   $\\forall w \\in V_u$\n",
    "\n",
    "---\n",
    "*Fuente: \"Material de Apoyo de unidad curricular Resistencia de Materiales 2\" FING*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tRgudPNtRNP"
   },
   "source": [
    "## Método de los elementos finitos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFT8qjCZOw2L"
   },
   "source": [
    "Identificamos un problema gobernado por ecuaciones en derivadas parciales (PDE) y buscamos la solución $u$, un campo de vectores tal que $u:\\Omega → \\mathbb{R}^n$ y tiene condición de borde $u_D$ en $\\partial \\Omega$. El método de los elementos finitos es una forma númerica para aproximar la solcuión de este tipo de ecuaciones en las cuales muchas veces no se tiene una solución exacta.\n",
    "\n",
    "El primer paso para aplicar el método es hallar la formulación débil del problema. Para esto usamos el teorema del trabajo virtual y lo que hacemos es a la PDE la multiplicamos por el campo de desplazamientos virtual $v$ y luego integramos en $\\Omega$. La idea es aplicar partes para reducir el orden de las derivadas lo máximo posible. También $v$ debe ser nulo en las partes del borde en donde $u$ estaba definido.\n",
    "\n",
    "Ahora tenemos un problema con formulación débil $a(u,v)=l(v)$ donde $u$ se la conoce como la función de prueba y $v$ como la función de testeo. Estas funciones viven en sus respectivos espacio de prueba $V$ y espacio de testeo $\\hat{V}$\n",
    "\n",
    "$u\\in V = \\{v \\in H^1(\\Omega):v=u_D$ en $\\partial \\Omega \\}$\n",
    "\n",
    "$v\\in \\hat{V} = \\{v \\in H^1(\\Omega):v=0$ en $\\partial \\Omega \\}$\n",
    "\n",
    "$H^1(\\Omega)$ es el *Espacio de Sobolev* que tiene funciones $v$ tal que $v^2$  y $|∇v |^2$ tienen integrales finitas en $Ω$, osea que son continuas. La solución al PDE debe tener también derivadas continuas pero esto no ocurre siempre en $H^1(\\Omega)$ ya que permite derivadas discontinuas. Esto permite usar polinomios a trozos. La formulación débil es un problema continuo: define la solución $u$ en un espacio de dimensión infinita $V$. El método de los elementos finitos (MEF) aproxima la solución cambiando el espacio $V$ por $V_h$ y $\\hat{V}_h$ en donde estos son discretos (dimensión finita) y cumplen $V_h \\subset V$ y $\\hat{V}_h \\subset \\hat{V}$. Así que la discretización de la formulación débil queda:\n",
    "\n",
    "encontrar $u_h \\in V_h$ tal que $a(u,v)=l(v)$, $\\forall v \\in \\hat{V}_h$\n",
    "\n",
    "En donde $a(u,v)$ es una forma bilineal y $l(v)$ es una forma lineal. Para la discretización de $V$ creamos un mallado, nomralmente de triangulos y tomamos vértices para interpolar un polinomio de grado m en ese triángulo (conocido como elemento finito). Las funciones de $V_h$ solo toman valores en estos vértices y para componente del campo tendría un nodo. Es decir que las funciones en $V_h$ estan definidas en #Vértices*n.\n",
    "\n",
    "Fuente: manual de fenics\n",
    "\n",
    "----\n",
    "\n",
    "Supongamos que conocemos una función $u_0$ en el conjunto de solución $V$ y las funciones $v_1,v_2,...,v_n$ en $\\hat{V}$ los desplazamientos virtuales.Supongamos además que conocemos que la solución $u$ del problema de elasticidad lineal puede ser hallada como combinación lineal: $u = u_0 + \\alpha_1v_1+\\alpha_2v_2+...+\\alpha_nv_n$. En donde $\\alpha_i$ son parámteros reales que desconocemos. Entonces el problema lo podemos ver como encontrar $u$ en $V´$ tal que $a(u,v)=l(v)$, $\\forall v \\in \\hat{V}´$. En donde $V´=\\{ u_0 + + \\alpha_1v_1+\\alpha_2v_2+...+\\alpha_nv_n: \\alpha_i\\in\\mathbb{R}\\}$ y $\\hat{V}´=\\{  \\beta_1v_1+\\beta_2v_2+...+\\beta_nv_n: \\beta_i\\in\\mathbb{R}\\}$\n",
    "\n",
    "\n",
    "\n",
    "A partir de la forma reducida del problema variacional, se plantea la siguiente expresión:\n",
    "\n",
    "$$\n",
    "a\\left( u_0 + \\sum_{j=1}^n \\alpha_j v_j,\\ \\sum_{i=1}^n \\beta_i v_i \\right) = l\\left( \\sum_{i=1}^n \\beta_i v_i \\right) \\quad \\forall \\beta \\in \\mathbb{R}^n\n",
    "$$\n",
    "\n",
    "Esta ecuación puede reescribirse como (Bilinealidad en $a$ y linealidad en $l$):\n",
    "\n",
    "$$\n",
    "\\sum_{j=1}^n \\sum_{i=1}^n \\beta_i \\alpha_j\\, a(v_j, v_i) = \\sum_{i=1}^n \\beta_i\\, l(v_i) - \\sum_{i=1}^n \\beta_ia(u_0, v_i) \\quad \\forall \\beta \\in \\mathbb{R}^n\n",
    "$$\n",
    "\n",
    "Definiendo:\n",
    "\n",
    "- $K_{ij} = a(v_j, v_i)$ como la matriz de componentes,\n",
    "- $F_i = l(v_i) - a(u_0, v_i)$ como el vector del lado derecho,\n",
    "- $\\alpha$ y $\\beta$ como los vectores de coeficientes,\n",
    "\n",
    "la expresión anterior se puede escribir de forma matricial como:\n",
    "\n",
    "$$\n",
    "\\beta^\\top K \\alpha = \\beta^\\top F \\quad \\forall \\beta \\in \\mathbb{R}^n\n",
    "$$\n",
    "\n",
    "y, por lo tanto, se deduce que:\n",
    "\n",
    "$$\n",
    "K \\alpha = F\n",
    "$$\n",
    "\n",
    "lo cual constituye el sistema reducido final a resolver donde $\\alpha_i$ son las incógnitas. Este sistema tiene solución ya que por **Lema 18.1** $K$ es simétrica y positiva lo que implica que $K$ es invertible y el sistema tiene solución.\n",
    "\n",
    "### Aproximar solución\n",
    "\n",
    "En general no es posible conocer $v_1,v_2,...,v_n$ que con $u_0$ nos permiten encontrar $u$ solución exacta del problema.\n",
    "\n",
    "Luego seguimos como en lo anterior discretizando el espacio de soluciones, y de esta forma las funciones $u,v$ se pueden ver como vectores que toman valores en los nodos.\n",
    "\n",
    "### Sobre la discretización\n",
    "\n",
    "Dividimos el cuerpo en figuras (elementos) menores que estos pueden ser: segmentos (una dimensión), triangulos o cuadrilateros (2 d) o tetraedros y hexaedros (3d). Para facilitar la integración usamos elementos de referencia (sería el triangulo derecho, con angulo recto) y lo llevamos al elemento con un cambio de variable\n",
    "\n",
    "### Condiciones de convergencia\n",
    "\n",
    "Veremos condiciones que garantizan que $u$ solucion de MEF converga a $u^*$ solución exacta. Sea m el orden más alto de las derivadas que aparecen, precisamos para garantizar convergencia:\n",
    "\n",
    "1. Regularidad de los elementos: $u \\in C^m$ para todo elemento en $\\Omega$\n",
    "\n",
    "2. Regularidad en todo el cuerpo: $u \\in C^{m-1}$ en las fronteras de los elementos\n",
    "\n",
    "3. Completitud: las funciones de forma de los elementos deben permitir representar polinomios de grado m\n",
    "\n",
    "### Sobre el error\n",
    "\n",
    "**Teormea de estimación de Aubin-Nitsche**\n",
    "Sea $u^*$ la solución exacta del problema de elasticidad lineal. Sea $u$ la solución hallada utilizando el método de elementos finitos, y sea su error $\\bar{e} = u^* - u$. Sea $h$ el tamaño máximo de todos los elementos de la malla utilizada, $m$ el orden más alto de las derivadas que aparecen en la energía de deformación, y $k$ el mayor grado del polinomio completo que pueden representar exactamente las funciones de forma de los elementos. Supongamos que la solución exacta $u^* \\in H^{k+1}(B, V_3)$. Entonces existe una constante real $c > 0$, independiente de $u^*$ y de $h$, tal que:\n",
    "\n",
    "$$\n",
    "\\| \\bar{e} \\|_s \\leq c h^\\beta \\|u^*\\|_{k+1},\n",
    "$$\n",
    "\n",
    "donde $s$ es cualquier número natural tal que $0 \\leq s \\leq k$, $\\beta$ es el número dado por $\\beta = \\min\\{k + 1 - s, 2(k + 1 - m)\\}$, y $\\| \\cdot \\|_s$ es la norma del espacio $H^s$.\n",
    "\n",
    "\n",
    "Esto nos dice que el error se puede reducir de 2 formas:\n",
    "1. Refinando la malla\n",
    "2. Aumentando el grado de los polinomios a interpolar\n",
    "\n",
    "### Grado de interpolación\n",
    "\n",
    "El grado del polinomio por el que vamos a interpolar me define la cantidad de nodos por elemento finito. Usaremos interpolación de Lagrange\n",
    "\n",
    "Ejemplo en 2 dimensiones si usamos un mallado de triángulos tenemos que si el polinomio es de grado 1 el polinomio tiene forma $a_0 + a_1x+ a_2y$ y por lo tanto precisamos 3 nodos (los vertices). Si el grado del polinomio es 2 tiene forma $a_0 + a_1x + a_2y + a_3x^2 + a_4y^2 + a_5xy$ luego tiene 6 nodos (los vertices y los puntos medios de los lados), etc.\n",
    "\n",
    "\n",
    "Fuente: Pdf elasticidad fing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNi0ZEedZ5jO"
   },
   "source": [
    "## Método de bases reducidas\n",
    "\n",
    "Es una estrategía para optimizar el método de los elementos finitos, resolviendo para una familia de ecuaciones de la forma $a(u,v)=l(v)$. La familia varía segun un parámetro $\\mu \\in \\mathbb{P}$ en donde $\\mathbb{P}$ define como puede variar ese parámetro. Entonces se mantiene el esquema original de la ecuacion solo que $a,l$ dependen de $\\mu$ y nuestra ecuación queda $a(u,v, \\mu)=l(v,\\mu)$. Una forma de ver esto puede ser si tenemos una barra apoyada de los lados que se le aplica una fuerza que quiero hacer variar si usa MEF para cada valor de fuerza que quiera probar tengo que volver a calcular. Acá usando BR tendría un espacio donde puede variar la fuerza $\\mu$ y no tendría que volver a calcular todo de 0 ya que es el mismo problema casi.\n",
    "\n",
    "Un modelo de orden reducido se puede construir como el span de un pequeño número de soluciones de alta fidelidad $u_\\delta(\\mu)$, llamadas *snapshots*, para diferentes valores del parámetro $\\mu$. Luego, para cada nuevo valor de $\\mu$, se calcula una solución sustituta $u_{rb}(\\mu)$, basada en el subespacio $N$-dimensional $V_{rb} \\subset V_\\delta$. La suposición crítica es que el ancho de Kolmogorov $n$ decrece rápidamente, es decir, $N \\ll N_\\delta$, lo que significa que el problema es reducible con una pequeña cantidad de modos.\n",
    "\n",
    "La aproximación de base reducida se puede formular de la siguiente manera: para cualquier $\\mu \\in \\mathbb{P}$, encontrar $u_{rb}(\\mu) \\in V_{rb}$ tal que\n",
    "\n",
    "$$\n",
    "a(u_{rb}(\\mu), v_{rb}; \\mu) = f(v_{rb}; \\mu), \\quad \\forall v_{rb} \\in V_{rb},\n",
    "$$\n",
    "\n",
    "La solución de base reducida se obtiene como una combinación lineal de la base reducida:\n",
    "\n",
    "$$\n",
    "u_{rb}(\\mu) = \\sum_{n=1}^{N} (u_\\mu^{rb})_n \\xi_n,\n",
    "$$\n",
    "\n",
    "donde el espacio de base reducida está dado por $V_{rb} = \\text{span}\\{\\xi_1, \\dots, \\xi_N\\}$. A partir de la inclusión $V_{rb} \\subset V_\\delta$ y la condición de coercividad, encontramos que el problema de base reducida es bien planteado; de hecho, se cumple que\n",
    "\n",
    "$$\n",
    "\\alpha_{rb}(\\mu) = \\inf_{v_{rb} \\neq 0 \\in V_{rb}} \\frac{a(v_{rb}, v_{rb}; \\mu)}{\\|v_{rb}\\|_V^2} \\geq \\inf_{v_\\delta \\neq 0 \\in V_\\delta} \\frac{a(v_\\delta, v_\\delta; \\mu)}{\\|v_\\delta\\|_V^2} = \\alpha_\\delta(\\mu) \\geq \\alpha > 0.\n",
    "$$\n",
    "\n",
    "\n",
    "Este problema lo descomponemos en 2. El primero es un problema que lleva más tiempo que conciste en hallar la base reducida, los snapshots, la idea es que esto pueda ser ejecutado sin supervisión, no tiene eque estar nadie presente. A esto le llamamos **etapa offline**. La segunda parte del problema consiste en hallar los multiplicadores de los vectores en la base reducida, la idea es que esta parte lleve el menor tiempo posible. A esto le llamamos **etapa online**.\n",
    "\n",
    "### **Fase offline**\n",
    "\n",
    "Existen varios métodos para lograr una base reducida. Cada uno con sus ventajas y desventajas. Explicaremos 3: elección aleatoría, POD y algoritmo greedy\n",
    "\n",
    "#### **Elección aleatoria**\n",
    "\n",
    "Una forma de elegir la base reducida es simplemente elegir al azar, utilizamos una distribución uniforme para elegir cada coordenada de los $\\mu_i$. Luego computamos para $\\mu_1 ... \\mu_N$ la solución utilizando MEF y colgando esas soluciones tenemos nuestra base reducida. Parece algo que no serviría pero en la práctica logra resultados aceptables.\n",
    "\n",
    "*Ventajas*\n",
    "*   Es el más sencillo de implementar\n",
    "*   La etapa offline es la más rápida\n",
    "*   No precisa conocer la formulación débil (si utilizamos algun software como AGE)\n",
    "\n",
    "*Contras*\n",
    "*   Es el método menos preciso de todos\n",
    "*   Requiere una dimensión mayor de base reducida lo que haría más lenta la etapa online\n",
    "*   Existe la posibilidad de que la elección aleatoria no sea buena\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### **Descomposición Ortogonal Propia (POD)**\n",
    "\n",
    "Una de las técnicas más utilizadas para la reducción de orden de modelos es la **descomposición ortogonal propia** (*Proper Orthogonal Decomposition*, POD). Esta técnica permite comprimir un conjunto de datos extrayendo los modos más representativos.\n",
    "\n",
    "El objetivo principal es encontrar un subespacio óptimo de dimensión $N$, $V_{rb}$, que minimice:\n",
    "\n",
    "$$\n",
    "\\frac{1}{M} \\sum_{\\mu \\in P_h} \\inf_{v_{rb} \\in V_{rb}} \\|u_\\delta(\\mu) - v_{rb}\\|_V^2\n",
    "$$\n",
    "\n",
    "donde $P_h \\subset P$ es una discretización del espacio de parámetros (que normalmente se escoje al azar), y $\\{ \\mu_1, \\dots, \\mu_M \\}$ son $M$ muestras de parámetros. Los correspondientes *snapshots* son $\\psi_i = u_\\delta(\\mu_i)$ (solución con MEF), para $i = 1, \\dots, M$, y se organizan en la matriz de snapshots $S \\in \\mathbb{R}^{N_\\delta \\times M}$ como:\n",
    "\n",
    "$$\n",
    "S = [\\psi_1 \\; | \\; \\psi_2 \\; | \\; \\dots \\; | \\; \\psi_M]\n",
    "$$\n",
    "\n",
    "La reducción mediante POD se obtiene aplicando una **descomposición en valores singulares** (SVD) a $S$:\n",
    "\n",
    "$$\n",
    "S = U \\Sigma V^*\n",
    "$$\n",
    "\n",
    "donde:\n",
    "- $U \\in \\mathbb{R}^{N_\\delta \\times M}$ y $V \\in \\mathbb{R}^{M \\times M}$ contienen los vectores singulares izquierdos y derechos, respectivamente,\n",
    "- $\\Sigma \\in \\mathbb{R}^{M \\times M}$ es una matriz diagonal con los valores singulares $\\lambda_1 \\geq \\dots \\geq \\lambda_M$.\n",
    "\n",
    "Para obtener una **aproximación de rango $r$**, se descartan los modos asociados a los valores singulares más pequeños $\\lambda_i$ para $i = r+1, \\dots, M$ y se conservan las primeras $r$ columnas de $U$ y filas de $V^*$, junto con la submatriz $\\Sigma$ de tamaño $r \\times r$.\n",
    "\n",
    "También se puede considerar la **matriz de correlación** $C = S^*S \\in \\mathbb{R}^{M \\times M}$, cuyos elementos son:\n",
    "\n",
    "$$\n",
    "C_{ij} = \\langle \\psi_i, \\psi_j \\rangle\n",
    "$$\n",
    "\n",
    "Para $N \\leq M$, la **base POD** está dada por los primeros $N$ autovectores $\\xi_1, \\dots, \\xi_N$ de la matriz $C$, que forman una base ortonormal del subespacio $V_{POD}$. Esta base minimiza la cantidad anterior.\n",
    "\n",
    "Si denotamos la **proyección ortogonal** $P_N : V \\rightarrow V_{POD}$ como:\n",
    "\n",
    "$$\n",
    "P_N[x] = \\sum_{n=1}^{N} (x, \\xi_n)_V \\, \\xi_n,\n",
    "$$\n",
    "\n",
    "entonces el error de aproximación queda relacionado con la decaída de los valores singulares por:\n",
    "\n",
    "$$\n",
    "\\frac{1}{M} \\sum_{i=1}^{M} \\| \\psi_i - P_N[\\psi_i] \\|_V^2 = \\sum_{i=N+1}^{M} \\lambda_i\n",
    "$$\n",
    "\n",
    "*Ventajas*\n",
    "*   Es muy preciso y no perjudica el tiempo de la fase online\n",
    "*   No precisa conocer la formulación débil (si utilizamos algun software como AGE)\n",
    "\n",
    "*Contras*\n",
    "*   Es muy lenta la etapa offline\n",
    "\n",
    "\n",
    "#### **Algoritmo greedy**\n",
    "\n",
    "Es un procedimiento iterativo en el cual una nueva $u_\\delta(\\mu)$ (solución para un valor $\\mu$ utilizando FEM) es añadida en cada iteración para mejorar la presición del espacio reducido\n",
    "\n",
    "**Algoritmo**\n",
    "\n",
    "Entrada: Valor de tolerancia (tol), la primer base reducida $V_{rb}=span(u_\\delta (\\mu_1))$ donde $\\mu_1$ es escogido al azar en nuestro espacio de parámetros discretizado también al azar. También n = 1 (tamaño de la base reducida)\n",
    "\n",
    "Salida: Obtenemos un espacio óptimo de base reducida $V_{rb}$\n",
    "\n",
    "Procedimiento:\n",
    "\n",
    "1. Computo $u_\\delta (\\mu_n)$ solucion por MEF para $\\mu_n$ y $V_{rb}=span(u_\\delta (\\mu_1),...,u_\\delta (\\mu_n))$\n",
    "\n",
    "2. Para todo $\\mu \\in \\mathbb{P}$ :\n",
    "\n",
    "3. Computo $u_{rb}(\\mu)$ solución base reducida para $\\mu$ (se ven cuales son los multiplicadores)\n",
    "\n",
    "4. Evaluo $\\eta(\\mu)$, el residuo $\\eta(\\mu)= \\max_{v} (a(u_{rb}(\\mu),v)-l(v))$\n",
    "\n",
    "5. Elijo $\\mu_{n+1} = \\arg \\max _{\\mu \\in \\mathbb{P}} \\eta(\\mu)$\n",
    "\n",
    "End for\n",
    "\n",
    "6. Si $\\eta(\\mu_{n+1})> tol$ entonces n=n+1 y empiezo devuelta\n",
    "\n",
    "7. Si no: FIN\n",
    "\n",
    "\n",
    "*Ventajas*\n",
    "\n",
    "* Es muy preciso y no perjudica el tiempo de la fase offline\n",
    "* Garantiza un espacio de base reducida óptimo\n",
    "\n",
    "*Contras*\n",
    "\n",
    "* Requiere conocer la ecuación\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqyjIBWUoqSO"
   },
   "source": [
    "### **Fase online**\n",
    "\n",
    "Nuestra solución en base reducida con parametro $\\mu$ es:\n",
    "$$\n",
    "u_{rb}(\\mu)=\\sum_{i=1}^N \\alpha_i u_{MEF}(\\mu_i)\n",
    "$$\n",
    "\n",
    "La idea de esta etapa es econtrar $\\alpha_1, \\alpha_2, ..., .\\alpha_N$ donde $N$ es el tamaño de nuestra base reducida. Elegimos un valor concreto para $\\mu \\in \\mathbb{P}$.\n",
    "\n",
    "Queremos que $u_{rb}(\\mu)$ cumpla $a(u_{rb}(\\mu),v_{rb};\\mu)=l(v_{rb};\\mu)$. El método de Galerkin indica que debemos tomar $v_{rb}$ como uno entre $\\{ u(\\mu_1),...,u(\\mu_N)\\}$. Luego tomemos $v_{rb}=u(\\mu_j)$ entonces queremos que $\\forall j \\in \\{1,...,N\\}$ se cumpla $a(u_{rb}(\\mu),u(\\mu_j);\\mu)=l(u(\\mu_j);\\mu)$\n",
    "\n",
    "Como $u_{rb}$ esta en la base reducida entonces podemos descomponerlo en sumas de elementos de nuestra base reducida:\n",
    "\n",
    "$$\n",
    "a(\\sum_{i=1}^N \\alpha_i u(\\mu_i),u(\\mu_j);\\mu)=l(u(\\mu_j);\\mu)\n",
    "$$\n",
    "\n",
    "Ahora haremos un razonamiento parecido a lo que hicimos para deducir la ecuación de MEF solo que ahora ambas funciones $a$ y $l$ dependen de $\\mu$. También los $\\alpha_i$ dependen de $\\mu$. Luego por linealida $\\forall j \\in \\{1,...,N\\}$\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^N \\alpha_i a(u(\\mu_i),u(\\mu_j),\\mu)=l(u(\\mu_j),\\mu)\n",
    "$$\n",
    "\n",
    "Si llamamos $K_{ij}=a(u(\\mu_i),u(\\mu_j),\\mu)$ y $L_j=l(u(\\mu_j),\\mu)$ podemos llevar este conjunto de ecuaciones (recordar que es para todo j) a uno con notación matricial $K\\alpha=L$ donde $\\alpha= (\\alpha_1,...,\\alpha_N)$.\n",
    "\n",
    "Esta ecuación es simplemente un sistema de ecuaciones lineales NxN y se puede resolver fácil y rápido con una computadora. La idea es que N sea lo menor posible para que esto se compute lo más rápido posible. También para hacer más rápida esta base la matriz $K$ se puede computar en la fase offline, ya que el $\\mu$ en nuestros ejemplos sería un multiplicador que afectaría a algunas secciones de la matriz o el vector $L$\n",
    "\n",
    "*Ventajas*\n",
    "* El tiempo que demora el programa con una persona enfrente es muy poco\n",
    "\n",
    "*Contras*\n",
    "* Requiere conocer la ecuación"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNhw+ek1FGeWkwqQhLGml/e",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
